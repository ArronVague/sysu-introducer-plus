# 大语言模型模块

在该模块内，主要对大模型进行加强与封装，
用于处理输入的消息，然后返回回答。
此部分的工作是在基础的 LLM 的基础上进行开发与增强，
本模块并不负责选择什么回答进行输入
（这部分由 DynamicMessageQueue 负责），
而是通过 **外部知识库**，**检索**和**提示工程**和提高回答的质量和风格。

## 架构设计

-   大模型内核: 此部分可以通过调用 API 或者使用本地部署的大模型，
    是整个模块中最基础的部分。
-   外部知识库：外部知识库则是通过关系型/向量数据库存储，
    并通过消息对知识库进行检索，提取出最关键的知识信息。
-   长期记忆（Optional）：大模型的每次生成结果都是有意义的，
    因此这些回答可以利用在未来的生成当中。长期记忆就是一个缓存，
    当问题命中时，就可以使用此处的缓存进行生成。
-   短期记忆（Optional）：用户在近期回答的问题会被标记，
    如果继续由相同的问题，大模型可能会表示厌烦的情绪。

> 这里的记忆系统可能和 DMQ 优点重合，
> 但是还是有所区别的。此处的记忆模块，更偏向于大脑的海马体，
> 而 DMQ 更偏向于人眼的注意力机制。
>
> 当然，后续可能将 DMQ 融入大语言模型内核中。

## 技术结构

### 1. 大模型内核

在本项目中，我们统一使用 `Bot` 对象来封装大模型的模块。
主要是通过 `talk` 函数来生成问题的回答。
在该对象内，我们可以对 API 调用 或本地部署的大模型进行封装。

```python
class Bot:
    def talk(self, message: str) -> str:
        ...
```

### 2. 外部知识库

为了增强大模型的知识库，我们将进行两方面的工作：**知识库构建** 和 **知识检索**。
对于前者，目前是使用人工进行搭建。
